{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIylcNjeuCyG",
        "outputId": "f1af5a6c-2923-4347-f563-bd9f4dfd1711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.2.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U scikit-learn\n",
        "!pip install -U imbalanced-learn scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from itertools import cycle\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Assuming Google Drive is mounted and the CSV file path is defined\n",
        "csv_file_path = '/content/drive/My Drive/Cleaned_data.csv'\n",
        "\n",
        "# Read the CSV file directly into a DataFrame\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Selecting relevant features for the model\n",
        "features = ['Number of vehicles involved', 'Crash year',\n",
        "            'Day of the week', 'Month of year', 'Is weekend', 'TLA (Territorial local authority)',\n",
        "\n",
        "            'Regional council', 'Road category', 'Intersection / midblock', 'Urban or open speed zone',\n",
        "            'Posted speed limit', 'Junction type', 'Road curvature', 'Road feature', 'Gradient',\n",
        "            'Surface type', 'Road type', 'Street lights', 'Number of lanes', 'Traffic control present',\n",
        "            'Primary surface condition', 'Road markings', 'Natural Light', 'Primary weather',\n",
        "            'Vehicle 1 type', 'Ethnicity', 'Gender', 'Road user type', 'Crash severity']\n",
        "data = data[features]\n",
        "\n",
        "# Handling missing values (Example approach, adjust according to your data)\n",
        "data.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    data[column] = label_encoder.fit_transform(data[column])\n",
        "\n",
        "# Separating the target variable and features\n",
        "X = data.drop('Crash severity', axis=1)\n",
        "y = data['Crash severity']\n",
        "\n",
        "\n",
        "# Convert categorical variables to numerical using one-hot encoding\n",
        "X = pd.get_dummies(data.drop('Crash severity', axis=1))\n",
        "y = data['Crash severity']\n",
        "\n",
        "\n",
        "# Split data into training (80%) and testing (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Further split training data to separate out a tuning set (10% of the original dataset)\n",
        "X_tune, X_not_tune, y_tune, y_not_tune = train_test_split(X_train, y_train, test_size=0.90, random_state=42)  # Adjusted to keep 10% for tuning\n",
        "\n",
        "# Apply SMOTE to the tuning data\n",
        "smote = SMOTE(random_state=42)\n",
        "X_tune_smote, y_tune_smote = smote.fit_resample(X_tune, y_tune)\n",
        "\n",
        "# Initialize RandomForestClassifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Define a simplified hyperparameter grid\n",
        "param_dist_simplified = {\n",
        "    'n_estimators': [100, 200, 300],  # Fewer options\n",
        "    'max_features': ['auto'],  # Simplified to default\n",
        "    'max_depth': [10, 20, None],  # Fewer options\n",
        "    'min_samples_split': [2, 4],  # Fewer options\n",
        "    'min_samples_leaf': [1, 2],  # Fewer options\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Initialize the RandomizedSearchCV with fewer iterations and default CV folds\n",
        "rf_random_simplified = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist_simplified,\n",
        "    n_iter=10,  # Fewer iterations\n",
        "    cv=5,  # Default value for CV\n",
        "    verbose=2,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "# Fit the model with the simplified search\n",
        "rf_random_simplified.fit(X_tune_smote, y_tune_smote)\n",
        "\n",
        "# Extract the best estimator from the simplified random search\n",
        "best_rf_simplified = rf_random_simplified.best_estimator_\n",
        "\n",
        "# Use the best estimator to make predictions on the test set\n",
        "y_pred = best_rf_simplified.predict(X_test)\n",
        "\n",
        "# Then proceed with your evaluation using y_pred as before\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Accuracy: {accuracy:.4f}\\nPrecision: {precision:.4f}\\nRecall: {recall:.4f}\\nF1-score: {f1:.4f}\")\n",
        "\n",
        "# And so on with the rest of your evaluation code...\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "HsjHn0IhFZ93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 836
        },
        "outputId": "7db4fd76-c145-428f-a3bd-32813412798d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6358\n",
            "Precision: 0.6074\n",
            "Recall: 0.6358\n",
            "F1-score: 0.6184\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.03      0.01      0.01       132\n",
            "           1       0.42      0.40      0.41      3765\n",
            "           2       0.73      0.80      0.77      8822\n",
            "           3       0.26      0.12      0.16       981\n",
            "\n",
            "    accuracy                           0.64     13700\n",
            "   macro avg       0.36      0.33      0.34     13700\n",
            "weighted avg       0.61      0.64      0.62     13700\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate model performance across different hyperparameters\n",
        "def evaluate_model_performance(clf, X_train, y_train, X_test, y_test, param_name, param_values):\n",
        "    performance = {}\n",
        "    for value in param_values:\n",
        "        kwargs = {param_name: value}\n",
        "        model = RandomForestClassifier(random_state=42, **kwargs)\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        performance[value] = {\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "            'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "            'F1': f1_score(y_test, y_pred, average='weighted')\n",
        "        }\n",
        "    return performance\n",
        "\n",
        "# Evaluating n_estimators\n",
        "n_estimators_list = [50, 100, 200, 300]\n",
        "n_estimators_performance = evaluate_model_performance(rf_clf, X_train, y_train, X_test, y_test, 'n_estimators', n_estimators_list)\n",
        "\n",
        "# Evaluating max_depth\n",
        "max_depth_values = [None, 10, 20, 30, 40, 50]\n",
        "max_depth_performance = evaluate_model_performance(rf_clf, X_train, y_train, X_test, y_test, 'max_depth', max_depth_values)\n",
        "\n",
        "# Evaluating min_samples_split and min_samples_leaf\n",
        "min_samples_split_values = [2, 4, 6, 10]\n",
        "min_samples_leaf_values = [1, 2, 4, 6]\n",
        "split_performance = evaluate_model_performance(rf_clf, X_train, y_train, X_test, y_test, 'min_samples_split', min_samples_split_values)\n",
        "leaf_performance = evaluate_model_performance(rf_clf, X_train, y_train, X_test, y_test, 'min_samples_leaf', min_samples_leaf_values)\n",
        "\n",
        "# Function to print performance metrics\n",
        "def print_performance(performance, param_name):\n",
        "    for param_value, metrics in performance.items():\n",
        "        print(f\"{param_name}: {param_value}, Metrics: {metrics}\")\n",
        "\n",
        "# Print performance metrics for different parameters\n",
        "print_performance(n_estimators_performance, \"n_estimators\")\n",
        "print_performance(max_depth_performance, \"max_depth\")\n",
        "print(\"min_samples_split performance:\")\n",
        "print_performance(split_performance, \"min_samples_split\")\n",
        "print(\"\\nmin_samples_leaf performance:\")\n",
        "print_performance(leaf_performance, \"min_samples_leaf\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sukvi9ShUsuO",
        "outputId": "94e3d363-fcda-4085-e46e-c6669b79cd39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators: 50, Metrics: {'Accuracy': 0.7020236731576938, 'Precision': 0.662162383047998, 'Recall': 0.7020236731576938, 'F1': 0.6521197554409495}\n",
            "n_estimators: 100, Metrics: {'Accuracy': 0.7058419243986255, 'Precision': 0.6673183389617924, 'Recall': 0.7058419243986255, 'F1': 0.6519586384933789}\n",
            "n_estimators: 200, Metrics: {'Accuracy': 0.709049255441008, 'Precision': 0.6729505229974171, 'Recall': 0.709049255441008, 'F1': 0.6533060639013121}\n",
            "n_estimators: 300, Metrics: {'Accuracy': 0.7076746849942727, 'Precision': 0.671665581327608, 'Recall': 0.7076746849942727, 'F1': 0.6505243591805633}\n",
            "max_depth: None, Metrics: {'Accuracy': 0.7058419243986255, 'Precision': 0.6673183389617924, 'Recall': 0.7058419243986255, 'F1': 0.6519586384933789}\n",
            "max_depth: 10, Metrics: {'Accuracy': 0.682626956853761, 'Precision': 0.6167851047060953, 'Recall': 0.682626956853761, 'F1': 0.5896744923606355}\n",
            "max_depth: 20, Metrics: {'Accuracy': 0.7024818633066056, 'Precision': 0.6729539863879352, 'Recall': 0.7024818633066056, 'F1': 0.631205093763525}\n",
            "max_depth: 30, Metrics: {'Accuracy': 0.7066055746468117, 'Precision': 0.6733961508895409, 'Recall': 0.7066055746468117, 'F1': 0.6462725682317805}\n",
            "max_depth: 40, Metrics: {'Accuracy': 0.7054600992745322, 'Precision': 0.6712388996049501, 'Recall': 0.7054600992745322, 'F1': 0.649582543137514}\n",
            "max_depth: 50, Metrics: {'Accuracy': 0.7046200840015273, 'Precision': 0.667806766983056, 'Recall': 0.7046200840015273, 'F1': 0.6500375401507057}\n",
            "min_samples_split performance:\n",
            "min_samples_split: 2, Metrics: {'Accuracy': 0.7058419243986255, 'Precision': 0.6673183389617924, 'Recall': 0.7058419243986255, 'F1': 0.6519586384933789}\n",
            "min_samples_split: 4, Metrics: {'Accuracy': 0.7042382588774342, 'Precision': 0.6654119476975833, 'Recall': 0.7042382588774342, 'F1': 0.6463029410525942}\n",
            "min_samples_split: 6, Metrics: {'Accuracy': 0.7052310042000763, 'Precision': 0.6678755965254937, 'Recall': 0.7052310042000763, 'F1': 0.6459339707363744}\n",
            "min_samples_split: 10, Metrics: {'Accuracy': 0.7077510500190912, 'Precision': 0.6733669446476915, 'Recall': 0.7077510500190912, 'F1': 0.6475558741997917}\n",
            "\n",
            "min_samples_leaf performance:\n",
            "min_samples_leaf: 1, Metrics: {'Accuracy': 0.7058419243986255, 'Precision': 0.6673183389617924, 'Recall': 0.7058419243986255, 'F1': 0.6519586384933789}\n",
            "min_samples_leaf: 2, Metrics: {'Accuracy': 0.7063764795723558, 'Precision': 0.6721354451876241, 'Recall': 0.7063764795723558, 'F1': 0.6437192543054264}\n",
            "min_samples_leaf: 4, Metrics: {'Accuracy': 0.7061473844978999, 'Precision': 0.6731766612370347, 'Recall': 0.7061473844978999, 'F1': 0.6387855025204151}\n",
            "min_samples_leaf: 6, Metrics: {'Accuracy': 0.7005727376861397, 'Precision': 0.6687542677824152, 'Recall': 0.7005727376861397, 'F1': 0.6278456718921157}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_sizes = [0.2, 0.3, 0.4]  # Different ratios for testing\n",
        "\n",
        "split_test_performance = {}\n",
        "\n",
        "for test_size in test_sizes:\n",
        "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    rf_model = RandomForestClassifier(random_state=42)\n",
        "    rf_model.fit(X_train_split, y_train_split)\n",
        "    y_pred_split = rf_model.predict(X_test_split)\n",
        "\n",
        "    split_test_performance[test_size] = {\n",
        "        'Accuracy': accuracy_score(y_test_split, y_pred_split),\n",
        "        'Precision': precision_score(y_test_split, y_pred_split, average='weighted'),\n",
        "        'Recall': recall_score(y_test_split, y_pred_split, average='weighted'),\n",
        "        'F1': f1_score(y_test_split, y_pred_split, average='weighted')\n",
        "    }\n",
        "\n",
        "# Print performances for different splits\n",
        "for test_size, metrics in split_test_performance.items():\n",
        "    print(f\"Test size: {test_size}, Metrics: {metrics}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq1nN2kGEao0",
        "outputId": "837c5d15-fc84-4928-e0b0-056d5ba05701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test size: 0.2, Metrics: {'Accuracy': 0.7058419243986255, 'Precision': 0.6673183389617924, 'Recall': 0.7058419243986255, 'F1': 0.6519586384933789}\n",
            "Test size: 0.3, Metrics: {'Accuracy': 0.7046276027083439, 'Precision': 0.6695132213484426, 'Recall': 0.7046276027083439, 'F1': 0.6492242575825625}\n",
            "Test size: 0.4, Metrics: {'Accuracy': 0.7004581901489118, 'Precision': 0.6619556132470258, 'Recall': 0.7004581901489118, 'F1': 0.6429160348058368}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from scipy.stats import randint\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from itertools import cycle\n",
        "from scipy import interp\n",
        "import numpy as np\n",
        "\n",
        "# Assuming Google Drive is mounted and CSV file path is defined\n",
        "\n",
        "# Initialize an empty list to store the rows\n",
        "rows = []\n",
        "\n",
        "# Open the file and read it with the csv.reader\n",
        "try:\n",
        "    with open(csv_file_path, 'r', encoding='utf-8') as file:\n",
        "        reader = csv.reader(file)\n",
        "        for row in reader:\n",
        "            rows.append(row)\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading the CSV file: {e}\")\n",
        "\n",
        "# Convert the list of rows to a DataFrame if rows were read successfully\n",
        "if rows:\n",
        "    data = pd.DataFrame(rows[1:], columns=rows[0])\n",
        "    # Selecting relevant features for the model\n",
        "    features = ['Simple / complex crash', 'Number of vehicles involved', 'Crash year',\n",
        "                'Day of the week', 'Month of year', 'Is weekend', 'TLA (Territorial local authority)',\n",
        "                'Regional council', 'Road category', 'Deprivation mesh block deprivation index',\n",
        "                'Intersection / midblock', 'Urban or open speed zone', 'Posted speed limit',\n",
        "                'Junction type', 'Road curvature', 'Road feature', 'Gradient', 'Surface type',\n",
        "                'Road type', 'Street lights', 'Number of lanes', 'Traffic control present',\n",
        "                'Primary surface condition', 'Road markings', 'Natural Light', 'Primary weather',\n",
        "                'Vehicle 1 type', 'Ethnicity', 'Gender', 'Road user type', 'Crash severity']\n",
        "\n",
        "    data = data[features]\n",
        "\n",
        "    # Separating the target variable before applying one-hot encoding\n",
        "    target_variable = 'Crash severity'\n",
        "    X = data.drop(target_variable, axis=1)\n",
        "    y = data[target_variable]\n",
        "\n",
        "    # Convert categorical variables to numerical using one-hot encoding\n",
        "    X_encoded = pd.get_dummies(X, columns=X.select_dtypes(include=['object']).columns)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use only 1% of the training data for hyperparameter tuning\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=0.99, random_state=42)\n",
        "\n",
        "# Define a hyperparameter distribution instead of a fixed grid\n",
        "param_dist = {\n",
        "    'max_depth': [None] + list(range(5, 21)),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Reduced parallelism\n",
        "random_search = RandomizedSearchCV(dt_clf, param_distributions=param_dist, n_iter=10, cv=3, scoring='accuracy', n_jobs=1, random_state=42)\n",
        "random_search.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Initialize the Decision Tree Classifier with best hyperparameters\n",
        "dt_clf_best = DecisionTreeClassifier(random_state=42, **best_params)\n",
        "\n",
        "# Train the model on the full training set\n",
        "dt_clf_best.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = dt_clf_best.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the Confusion Matrix\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 923
        },
        "id": "NMGW16CgSdR7",
        "outputId": "8310ea89-1f52-4a17-d83e-447de907f673"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 16}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6951\n",
            "Precision: 0.6662\n",
            "Recall: 0.6951\n",
            "F1-score: 0.6237\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "     Fatal Crash       0.00      0.00      0.00       132\n",
            "     Minor Crash       0.66      0.20      0.30      3765\n",
            "Non-Injury Crash       0.70      0.98      0.82      8822\n",
            "   Serious Crash       0.45      0.11      0.17       981\n",
            "\n",
            "        accuracy                           0.70     13700\n",
            "       macro avg       0.45      0.32      0.32     13700\n",
            "    weighted avg       0.67      0.70      0.62     13700\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Function to evaluate Decision Tree model performance across different hyperparameter values\n",
        "def evaluate_decision_tree_performance(param_name, param_values):\n",
        "    performance = {}\n",
        "    for value in param_values:\n",
        "        dt_clf = DecisionTreeClassifier(random_state=42, **{param_name: value})\n",
        "        dt_clf.fit(X_train, y_train)\n",
        "        y_pred = dt_clf.predict(X_test)\n",
        "        performance[value] = {\n",
        "            'Accuracy': accuracy_score(y_test, y_pred),\n",
        "            'Precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "            'Recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "            'F1': f1_score(y_test, y_pred, average='weighted')\n",
        "        }\n",
        "    return performance\n",
        "\n",
        "# Define hyperparameter ranges\n",
        "max_depth_values = [None] + list(range(5, 26, 5))\n",
        "min_samples_split_values = range(2, 21, 4)\n",
        "min_samples_leaf_values = range(1, 11, 2)\n",
        "criterion_values = ['gini', 'entropy']\n",
        "\n",
        "# Evaluate model performance for each hyperparameter\n",
        "max_depth_performance = evaluate_decision_tree_performance('max_depth', max_depth_values)\n",
        "min_samples_split_performance = evaluate_decision_tree_performance('min_samples_split', min_samples_split_values)\n",
        "min_samples_leaf_performance = evaluate_decision_tree_performance('min_samples_leaf', min_samples_leaf_values)\n",
        "criterion_performance = evaluate_decision_tree_performance('criterion', criterion_values)\n",
        "\n",
        "# Print performances for different hyperparameters\n",
        "def print_performance(performance, param_name):\n",
        "    print(f\"Performance for different values of {param_name}:\")\n",
        "    for param_value, metrics in performance.items():\n",
        "        print(f\"{param_name} = {param_value}, Metrics: {metrics}\")\n",
        "\n",
        "print_performance(max_depth_performance, \"max_depth\")\n",
        "print_performance(min_samples_split_performance, \"min_samples_split\")\n",
        "print_performance(min_samples_leaf_performance, \"min_samples_leaf\")\n",
        "print_performance(criterion_performance, \"criterion\")\n",
        "\n",
        "print(\"Sensitivity analysis completed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_UrfpgPadFX",
        "outputId": "819cdbf9-ff77-4e15-b596-99e04abed4ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance for different values of max_depth:\n",
            "max_depth = None, Metrics: {'Accuracy': 0.6197810218978103, 'Precision': 0.6200779714255849, 'Recall': 0.6197810218978103, 'F1': 0.6198528642866035}\n",
            "max_depth = 5, Metrics: {'Accuracy': 0.6964963503649635, 'Precision': 0.6698083792424432, 'Recall': 0.6964963503649635, 'F1': 0.6269451186130264}\n",
            "max_depth = 10, Metrics: {'Accuracy': 0.7184671532846715, 'Precision': 0.6920718592292815, 'Recall': 0.7184671532846715, 'F1': 0.6624786521889938}\n",
            "max_depth = 15, Metrics: {'Accuracy': 0.710948905109489, 'Precision': 0.674090889725098, 'Recall': 0.710948905109489, 'F1': 0.6632706950120225}\n",
            "max_depth = 20, Metrics: {'Accuracy': 0.6911678832116789, 'Precision': 0.6503763856588454, 'Recall': 0.6911678832116789, 'F1': 0.6557756112287442}\n",
            "max_depth = 25, Metrics: {'Accuracy': 0.6732116788321167, 'Precision': 0.6377737850638573, 'Recall': 0.6732116788321167, 'F1': 0.647316416832042}\n",
            "Performance for different values of min_samples_split:\n",
            "min_samples_split = 2, Metrics: {'Accuracy': 0.6197810218978103, 'Precision': 0.6200779714255849, 'Recall': 0.6197810218978103, 'F1': 0.6198528642866035}\n",
            "min_samples_split = 6, Metrics: {'Accuracy': 0.6247445255474453, 'Precision': 0.6254943042438479, 'Recall': 0.6247445255474453, 'F1': 0.624619709183477}\n",
            "min_samples_split = 10, Metrics: {'Accuracy': 0.6256934306569343, 'Precision': 0.6258925089276328, 'Recall': 0.6256934306569343, 'F1': 0.6249270083852588}\n",
            "min_samples_split = 14, Metrics: {'Accuracy': 0.6318248175182481, 'Precision': 0.6286530601733448, 'Recall': 0.6318248175182481, 'F1': 0.6292798524937201}\n",
            "min_samples_split = 18, Metrics: {'Accuracy': 0.6390510948905109, 'Precision': 0.6315003797188043, 'Recall': 0.6390510948905109, 'F1': 0.6341660767646232}\n",
            "Performance for different values of min_samples_leaf:\n",
            "min_samples_leaf = 1, Metrics: {'Accuracy': 0.6197810218978103, 'Precision': 0.6200779714255849, 'Recall': 0.6197810218978103, 'F1': 0.6198528642866035}\n",
            "min_samples_leaf = 3, Metrics: {'Accuracy': 0.6353284671532847, 'Precision': 0.6290298261742052, 'Recall': 0.6353284671532847, 'F1': 0.6315586950552738}\n",
            "min_samples_leaf = 5, Metrics: {'Accuracy': 0.658029197080292, 'Precision': 0.6432002510554732, 'Recall': 0.658029197080292, 'F1': 0.6480322281712417}\n",
            "min_samples_leaf = 7, Metrics: {'Accuracy': 0.6589051094890511, 'Precision': 0.6386563142493789, 'Recall': 0.6589051094890511, 'F1': 0.6450732282607151}\n",
            "min_samples_leaf = 9, Metrics: {'Accuracy': 0.6672262773722628, 'Precision': 0.6437199602500073, 'Recall': 0.6672262773722628, 'F1': 0.651485394718089}\n",
            "Performance for different values of criterion:\n",
            "criterion = gini, Metrics: {'Accuracy': 0.6197810218978103, 'Precision': 0.6200779714255849, 'Recall': 0.6197810218978103, 'F1': 0.6198528642866035}\n",
            "criterion = entropy, Metrics: {'Accuracy': 0.6200729927007299, 'Precision': 0.6238035447613436, 'Recall': 0.6200729927007299, 'F1': 0.6218624464036022}\n",
            "Sensitivity analysis completed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Assuming 'X_encoded' and 'y' are already defined as your feature set and target variable after preprocessing\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Use only a small portion of the training data for hyperparameter tuning to save computation\n",
        "X_train_sample, _, y_train_sample, _ = train_test_split(X_train, y_train, test_size=0.99, random_state=42)\n",
        "\n",
        "# Define a hyperparameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'max_depth': [None] + list(range(5, 21)),\n",
        "    'min_samples_split': randint(2, 20),\n",
        "    'min_samples_leaf': randint(1, 10),\n",
        "    'criterion': ['gini', 'entropy']\n",
        "}\n",
        "\n",
        "# Initialize the Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "# Perform hyperparameter tuning using RandomizedSearchCV on the sample\n",
        "# Reduced parallelism\n",
        "random_search = RandomizedSearchCV(dt_clf, param_distributions=param_dist, n_iter=10, cv=3, scoring='accuracy', n_jobs=1, random_state=42)\n",
        "random_search.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "random_search.fit(X_train_sample, y_train_sample)\n",
        "\n",
        "# Get the best hyperparameters from the random search\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Re-run the sensitivity analysis with the best hyperparameters across different test sizes\n",
        "test_sizes = [0.2, 0.3, 0.4]  # Different ratios for testing\n",
        "split_test_performance_dt = {}\n",
        "\n",
        "for test_size in test_sizes:\n",
        "    # Split the data with the current test size\n",
        "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_encoded, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Initialize the Decision Tree Classifier with the best hyperparameters\n",
        "    dt_model_best = DecisionTreeClassifier(random_state=42, **best_params)\n",
        "\n",
        "    # Train the model with the best hyperparameters\n",
        "    dt_model_best.fit(X_train_split, y_train_split)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_split = dt_model_best.predict(X_test_split)\n",
        "\n",
        "    # Calculate and store performance metrics\n",
        "    split_test_performance_dt[test_size] = {\n",
        "        'Accuracy': accuracy_score(y_test_split, y_pred_split),\n",
        "        'Precision': precision_score(y_test_split, y_pred_split, average='weighted'),\n",
        "        'Recall': recall_score(y_test_split, y_pred_split, average='weighted'),\n",
        "        'F1': f1_score(y_test_split, y_pred_split, average='weighted')\n",
        "    }\n",
        "\n",
        "# Print performances for different test sizes with the best hyperparameters\n",
        "for test_size, metrics in split_test_performance_dt.items():\n",
        "    print(f\"Test size: {test_size} - Metrics: {metrics}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xfTB5uGobCTW",
        "outputId": "f9ec5376-c5d3-474a-c410-26bd97474eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_leaf': 4, 'min_samples_split': 16}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test size: 0.2 - Metrics: {'Accuracy': 0.6951094890510949, 'Precision': 0.666152588613992, 'Recall': 0.6951094890510949, 'F1': 0.623730169057863}\n",
            "Test size: 0.3 - Metrics: {'Accuracy': 0.6944525547445255, 'Precision': 0.6636337738011562, 'Recall': 0.6944525547445255, 'F1': 0.6227366773190056}\n",
            "Test size: 0.4 - Metrics: {'Accuracy': 0.6922262773722627, 'Precision': 0.6444533191091998, 'Recall': 0.6922262773722627, 'F1': 0.6157733021010899}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score\n",
        "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_curve, auc\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder, LabelBinarizer\n",
        "from scipy.stats import randint, uniform\n",
        "import numpy as np\n",
        "import lightgbm as lgb\n",
        "from itertools import cycle\n",
        "\n",
        "# Assuming Google Drive is mounted and the CSV file path is defined\n",
        "csv_file_path = '/content/drive/My Drive/Cleaned_data.csv'\n",
        "\n",
        "# Read the CSV file directly into a DataFrame\n",
        "data = pd.read_csv(csv_file_path)\n",
        "\n",
        "# Selecting relevant features for the model\n",
        "features = ['Number of vehicles involved', 'Crash year',\n",
        "            'Day of the week', 'Month of year', 'Is weekend', 'TLA (Territorial local authority)',\n",
        "\n",
        "            'Regional council', 'Road category', 'Intersection / midblock', 'Urban or open speed zone',\n",
        "            'Posted speed limit', 'Junction type', 'Road curvature', 'Road feature', 'Gradient',\n",
        "            'Surface type', 'Road type', 'Street lights', 'Number of lanes', 'Traffic control present',\n",
        "            'Primary surface condition', 'Road markings', 'Natural Light', 'Primary weather',\n",
        "            'Vehicle 1 type', 'Ethnicity', 'Gender', 'Road user type', 'Crash severity']\n",
        "data = data[features]\n",
        "\n",
        "# Handling missing values (Example approach, adjust according to your data)\n",
        "data.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Encoding categorical variables\n",
        "label_encoder = LabelEncoder()\n",
        "for column in data.select_dtypes(include=['object']).columns:\n",
        "    data[column] = label_encoder.fit_transform(data[column])\n",
        "\n",
        "# Separating the target variable and features\n",
        "X = data.drop('Crash severity', axis=1)\n",
        "y = data['Crash severity']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Apply SMOTE to balance the training data\n",
        "smote = SMOTE()\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Define a parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'learning_rate': uniform(0.01, 0.3),\n",
        "    'num_leaves': randint(20, 50),\n",
        "    'feature_fraction': uniform(0.8, 0.2),\n",
        "    'bagging_fraction': uniform(0.8, 0.2),\n",
        "    'bagging_freq': randint(1, 10)\n",
        "}\n",
        "\n",
        "# Use a subset of data for tuning (1% of the training data)\n",
        "X_sample, _, y_sample, _ = train_test_split(X_train_smote, y_train_smote, test_size=0.80, random_state=42)\n",
        "\n",
        "# Initialize the LightGBM model\n",
        "gbm = lgb.LGBMClassifier(objective='multiclass', num_class=len(np.unique(y_train_smote)), random_state=42)\n",
        "\n",
        "# Reduced parallelism\n",
        "random_search = RandomizedSearchCV(estimator=gbm, param_distributions=param_dist, n_iter=10, cv=3, scoring='accuracy', n_jobs=1, random_state=42)\n",
        "\n",
        "# Replace special JSON characters in feature names\n",
        "X_train_smote.columns = [col.replace('{', '').replace('}', '').replace(':', '').replace(';', '').replace(',', '') for col in X_train_smote.columns]\n",
        "X_test.columns = [col.replace('{', '').replace('}', '').replace(':', '').replace(';', '').replace(',', '') for col in X_test.columns]\n",
        "\n",
        "# After updating the feature names, rerun the model fitting process\n",
        "random_search.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "\n",
        "\n",
        "# Best parameters found\n",
        "best_params = random_search.best_params_\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "\n",
        "# Train the model with the best parameters on the full training data\n",
        "best_gbm = lgb.LGBMClassifier(**best_params, objective='multiclass', num_class=len(np.unique(y_train_smote)), random_state=42)\n",
        "best_gbm.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "# Predict on the test data\n",
        "y_pred = best_gbm.predict(X_test)\n",
        "\n",
        "# Calculate and print metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
        "\n",
        "# Print the classification report\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Display the confusion matrix\n",
        "confusion = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion, annot=True, fmt='d', cmap='Blues')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zWzENHKuOBqn",
        "outputId": "b0470206-5232-4cd0-fee5-927f81b1dff6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022961 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023367 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022643 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9197316968394074, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9197316968394074\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8749080237694725, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8749080237694725\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024698 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022872 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032283 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8667417222278044, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8667417222278044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8199949831636006, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8199949831636006\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023388 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022921 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022991 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.944399754453365, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.944399754453365\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8041168988591605, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8041168988591605\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023077 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022609 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023083 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9234963019255433, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9234963019255433\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8363649934414201, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8363649934414201\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023722 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022518 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022871 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9049549320516779, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049549320516779\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8863890037284232, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8863890037284232\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023248 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022488 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.032034 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023801 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.026097 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023193 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.936061507717556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.936061507717556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8092900825439996, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8092900825439996\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.024378 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022688 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023292 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8770833005079832, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8770833005079832\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9897771074506667, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9897771074506667\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023180 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033181 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.023026 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9219993315565242, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9219993315565242\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9368466053024315, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9368466053024315\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.022930 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 735\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071866 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 726\n",
            "[LightGBM] [Info] Number of data points in the train set: 93845, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Info] Start training from score -1.386262\n",
            "[LightGBM] [Info] Start training from score -1.386305\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031069 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 724\n",
            "[LightGBM] [Info] Number of data points in the train set: 93846, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386273\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Info] Start training from score -1.386316\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8364472175576125, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8364472175576125\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9818640804157565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9818640804157565\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.033556 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 730\n",
            "[LightGBM] [Info] Number of data points in the train set: 140768, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "Best Hyperparameters: {'bagging_fraction': 0.9947511037682919, 'bagging_freq': 3, 'feature_fraction': 0.8764923982534326, 'learning_rate': 0.3049692657420365, 'num_leaves': 44}\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.034282 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 730\n",
            "[LightGBM] [Info] Number of data points in the train set: 140768, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "Accuracy: 0.6793, Precision: 0.6515, Recall: 0.6793, F1-score: 0.6611\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.11      0.08      0.09       132\n",
            "           1       0.51      0.41      0.45      3765\n",
            "           2       0.76      0.86      0.81      8822\n",
            "           3       0.29      0.18      0.23       981\n",
            "\n",
            "    accuracy                           0.68     13700\n",
            "   macro avg       0.42      0.38      0.39     13700\n",
            "weighted avg       0.65      0.68      0.66     13700\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'X' and 'y' are your dataset's features and target variable\n",
        "# Assuming 'best_params' contains the best hyperparameters found by RandomizedSearchCV\n",
        "\n",
        "test_sizes = [0.2, 0.3, 0.4]\n",
        "split_test_performance_lgbm = {}\n",
        "\n",
        "for test_size in test_sizes:\n",
        "    # Split the data with the current test size\n",
        "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Apply SMOTE to balance the split training data\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train_split, y_train_split)\n",
        "\n",
        "    # Update feature names for LightGBM compatibility\n",
        "    X_train_smote.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in X_train_smote.columns]\n",
        "    X_test_split.columns = [\"\".join(c if c.isalnum() else \"_\" for c in str(x)) for x in X_test_split.columns]\n",
        "\n",
        "    # Initialize the LightGBM model with the best hyperparameters\n",
        "    gbm_best = lgb.LGBMClassifier(**best_params, objective='multiclass', random_state=42, num_class=len(np.unique(y_train_smote)))\n",
        "\n",
        "    # Train the model with the best hyperparameters on the split data\n",
        "    gbm_best.fit(X_train_smote, y_train_smote)\n",
        "\n",
        "    # Predict on the test set\n",
        "    y_pred_split = gbm_best.predict(X_test_split)\n",
        "\n",
        "    # Calculate and store performance metrics\n",
        "    split_test_performance_lgbm[test_size] = {\n",
        "        'Accuracy': accuracy_score(y_test_split, y_pred_split),\n",
        "        'Precision': precision_score(y_test_split, y_pred_split, average='weighted'),\n",
        "        'Recall': recall_score(y_test_split, y_pred_split, average='weighted'),\n",
        "        'F1': f1_score(y_test_split, y_pred_split, average='weighted')\n",
        "    }\n",
        "\n",
        "# Print performances for different test sizes with the best hyperparameters\n",
        "print(\"Sensitivity analysis for LightGBM with the best hyperparameters:\\n\")\n",
        "for test_size, metrics in split_test_performance_lgbm.items():\n",
        "    print(f\"Test size: {test_size}\")\n",
        "    for metric_name, metric_value in metrics.items():\n",
        "        print(f\"  {metric_name}: {metric_value:.4f}\")\n",
        "    print()  # For better readability between different test sizes\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tb-B7mt0lTKF",
        "outputId": "55e0a6a3-8036-4f7e-b2bb-10eaff7ce714"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214661 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 732\n",
            "[LightGBM] [Info] Number of data points in the train set: 140768, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035619 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 734\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.031441 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 733\n",
            "[LightGBM] [Info] Number of data points in the train set: 105704, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8764923982534326, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8764923982534326\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9947511037682919, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9947511037682919\n",
            "Sensitivity analysis for LightGBM with the best hyperparameters:\n",
            "\n",
            "Test size: 0.2\n",
            "  Accuracy: 0.6793\n",
            "  Precision: 0.6511\n",
            "  Recall: 0.6793\n",
            "  F1: 0.6610\n",
            "\n",
            "Test size: 0.3\n",
            "  Accuracy: 0.6799\n",
            "  Precision: 0.6522\n",
            "  Recall: 0.6799\n",
            "  F1: 0.6617\n",
            "\n",
            "Test size: 0.4\n",
            "  Accuracy: 0.6768\n",
            "  Precision: 0.6488\n",
            "  Recall: 0.6768\n",
            "  F1: 0.6581\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import lightgbm as lgb\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "X_encoded = pd.get_dummies(X)\n",
        "\n",
        "# Assuming 'X' and 'y' are defined somewhere in your code\n",
        "# X_encoded = pd.get_dummies(X)\n",
        "\n",
        "# Function to sample values for continuous hyperparameters\n",
        "def sample_uniform(start, width, num_samples=3):\n",
        "    return np.random.uniform(start, start + width, num_samples)\n",
        "\n",
        "# Evaluation function for LightGBM performance without varying test sizes\n",
        "def evaluate_lightgbm_performance(X_encoded, y, hyperparameters, continuous_params):\n",
        "    # Fixed test size for this evaluation\n",
        "    test_size = 0.3  # You can adjust this fixed test size as needed\n",
        "\n",
        "    # Splitting the data\n",
        "    X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_encoded, y, test_size=test_size, random_state=42)\n",
        "    smote = SMOTE()\n",
        "    X_train_smote, y_train_smote = smote.fit_resample(X_train_split, y_train_split)\n",
        "\n",
        "    # Correcting column sanitization for DataFrames converted from numpy arrays\n",
        "    X_train_smote = pd.DataFrame(X_train_smote, columns=[col.replace('{', '').replace('}', '').replace(':', '').replace(';', '').replace(',', '') for col in X_train_split.columns])\n",
        "    X_test_split = pd.DataFrame(X_test_split, columns=[col.replace('{', '').replace('}', '').replace(':', '').replace(';', '').replace(',', '') for col in X_test_split.columns])\n",
        "\n",
        "    # Performance storage\n",
        "    performance_metrics = {}\n",
        "\n",
        "    for param, values in hyperparameters.items():\n",
        "        if param in continuous_params:\n",
        "            # Sample values for continuous parameters\n",
        "            values = sample_uniform(*continuous_params[param], num_samples=3)\n",
        "\n",
        "        for value in values:\n",
        "            params = {'random_state': 42}\n",
        "            params[param] = value\n",
        "            # Adding other continuous parameters with fixed sampled value for this iteration\n",
        "            for cp in ['feature_fraction', 'bagging_fraction']:\n",
        "                if cp not in params:  # Ensure we don't overwrite the parameter being iterated\n",
        "                    params[cp] = sample_uniform(*continuous_params[cp], 1)[0]\n",
        "\n",
        "            # Model training and evaluation\n",
        "            model = lgb.LGBMClassifier(**params, objective='multiclass', num_class=len(np.unique(y_train_smote)))\n",
        "            model.fit(X_train_smote, y_train_smote)\n",
        "            y_pred_split = model.predict(X_test_split)\n",
        "\n",
        "            # Calculate and store performance metrics\n",
        "            performance_metrics[f\"{param}={value}\"] = {\n",
        "                'Accuracy': accuracy_score(y_test_split, y_pred_split),\n",
        "                'Precision': precision_score(y_test_split, y_pred_split, average='weighted'),\n",
        "                'Recall': recall_score(y_test_split, y_pred_split, average='weighted'),\n",
        "                'F1': f1_score(y_test_split, y_pred_split, average='weighted')\n",
        "            }\n",
        "\n",
        "    # Print performance metrics for each hyperparameter setting\n",
        "    for setting, metrics in performance_metrics.items():\n",
        "        print(f\"Setting: {setting}, Metrics: {metrics}\")\n",
        "\n",
        "# Hyperparameters and continuous parameters definition\n",
        "hyperparameters = {\n",
        "    'learning_rate': [0.1, 0.2, 0.3],\n",
        "    'num_leaves': [20, 30, 40],\n",
        "    'max_depth': [5, 10, 15],\n",
        "    'bagging_freq': [1, 5, 10]  # Discrete values for bagging_freq\n",
        "}\n",
        "continuous_params = {\n",
        "    'feature_fraction': (0.8, 0.2),\n",
        "    'bagging_fraction': (0.8, 0.2)\n",
        "}\n",
        "\n",
        "# Assuming 'X_encoded' and 'y' are defined earlier in your code\n",
        "evaluate_lightgbm_performance(X_encoded, y, hyperparameters, continuous_params)\n"
      ],
      "metadata": {
        "id": "NLuK0_4InmGa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bf3e5f5-cb77-4809-e191-e887068c7f27"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.860173863334473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.860173863334473\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8351249811272536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8351249811272536\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.860173863334473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.860173863334473\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8351249811272536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8351249811272536\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.053017 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] feature_fraction is set=0.860173863334473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.860173863334473\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8351249811272536, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8351249811272536\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9741856593258422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9741856593258422\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9633671662529425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9633671662529425\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9741856593258422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9741856593258422\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9633671662529425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9633671662529425\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030791 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9741856593258422, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9741856593258422\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9633671662529425, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9633671662529425\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9579072667400556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9579072667400556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8172787032918432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172787032918432\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9579072667400556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9579072667400556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8172787032918432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172787032918432\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.043094 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9579072667400556, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9579072667400556\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8172787032918432, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8172787032918432\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8292886926702759, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8292886926702759\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8415740563689813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8415740563689813\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8292886926702759, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8292886926702759\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8415740563689813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8415740563689813\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029460 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8292886926702759, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8292886926702759\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8415740563689813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8415740563689813\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9248303090640333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9248303090640333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9082781998109253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9082781998109253\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9248303090640333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9248303090640333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9082781998109253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9082781998109253\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029992 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9248303090640333, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9248303090640333\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9082781998109253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9082781998109253\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9838776686311913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9838776686311913\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9726497056712751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9726497056712751\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9838776686311913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9838776686311913\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9726497056712751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9726497056712751\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.044242 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9838776686311913, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9838776686311913\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9726497056712751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9726497056712751\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8392480199229071, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8392480199229071\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9219009503851978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9219009503851978\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8392480199229071, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8392480199229071\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9219009503851978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9219009503851978\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.029371 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8392480199229071, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8392480199229071\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9219009503851978, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9219009503851978\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] feature_fraction is set=0.846912911947216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.846912911947216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8737069191969198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8737069191969198\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.846912911947216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.846912911947216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8737069191969198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8737069191969198\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030663 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] feature_fraction is set=0.846912911947216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.846912911947216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8737069191969198, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8737069191969198\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8622539589789154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8622539589789154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9169725803792503, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9169725803792503\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8622539589789154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8622539589789154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9169725803792503, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9169725803792503\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.036685 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8622539589789154, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8622539589789154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9169725803792503, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9169725803792503\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8775356548155626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8775356548155626\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9072066384478583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9072066384478583\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8775356548155626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8775356548155626\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9072066384478583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9072066384478583\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030606 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8775356548155626, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8775356548155626\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9072066384478583, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9072066384478583\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9071612211762986, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071612211762986\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8626059161306969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8626059161306969\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9071612211762986, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071612211762986\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8626059161306969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8626059161306969\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030468 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9071612211762986, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9071612211762986\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8626059161306969, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8626059161306969\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9622142296548926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9622142296548926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.870197403107709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.870197403107709\n",
            "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9622142296548926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9622142296548926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.870197403107709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.870197403107709\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.030186 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 731\n",
            "[LightGBM] [Info] Number of data points in the train set: 123140, number of used features: 28\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Info] Start training from score -1.386294\n",
            "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
            "[LightGBM] [Warning] feature_fraction is set=0.9622142296548926, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9622142296548926\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.870197403107709, subsample=1.0 will be ignored. Current value: bagging_fraction=0.870197403107709\n",
            "Setting: learning_rate=0.1, Metrics: {'Accuracy': 0.6728467153284672, 'Precision': 0.6496622267337765, 'Recall': 0.6728467153284672, 'F1': 0.655961763794311}\n",
            "Setting: learning_rate=0.2, Metrics: {'Accuracy': 0.6817031630170316, 'Precision': 0.6550377978263738, 'Recall': 0.6817031630170316, 'F1': 0.662585604501092}\n",
            "Setting: learning_rate=0.3, Metrics: {'Accuracy': 0.6826277372262773, 'Precision': 0.6552207700798939, 'Recall': 0.6826277372262773, 'F1': 0.6638421190395655}\n",
            "Setting: num_leaves=20, Metrics: {'Accuracy': 0.6647688564476886, 'Precision': 0.646509254192728, 'Recall': 0.6647688564476886, 'F1': 0.6510479331400049}\n",
            "Setting: num_leaves=30, Metrics: {'Accuracy': 0.6712895377128953, 'Precision': 0.6483380431825532, 'Recall': 0.6712895377128953, 'F1': 0.6547346712234966}\n",
            "Setting: num_leaves=40, Metrics: {'Accuracy': 0.6743065693430657, 'Precision': 0.6499915920815302, 'Recall': 0.6743065693430657, 'F1': 0.6566040910774655}\n",
            "Setting: max_depth=5, Metrics: {'Accuracy': 0.6504622871046228, 'Precision': 0.6459366887742766, 'Recall': 0.6504622871046228, 'F1': 0.6467274525781593}\n",
            "Setting: max_depth=10, Metrics: {'Accuracy': 0.6707055961070559, 'Precision': 0.6498173697257701, 'Recall': 0.6707055961070559, 'F1': 0.6555480223327014}\n",
            "Setting: max_depth=15, Metrics: {'Accuracy': 0.6762043795620438, 'Precision': 0.6534465751388135, 'Recall': 0.6762043795620438, 'F1': 0.6596906970733887}\n",
            "Setting: bagging_freq=1, Metrics: {'Accuracy': 0.6724087591240876, 'Precision': 0.6507175794366583, 'Recall': 0.6724087591240876, 'F1': 0.6563311912518487}\n",
            "Setting: bagging_freq=5, Metrics: {'Accuracy': 0.6735279805352798, 'Precision': 0.6501510059222337, 'Recall': 0.6735279805352798, 'F1': 0.6562257411878281}\n",
            "Setting: bagging_freq=10, Metrics: {'Accuracy': 0.6762043795620438, 'Precision': 0.6525384763674438, 'Recall': 0.6762043795620438, 'F1': 0.658850056288622}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}